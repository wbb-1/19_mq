# 跨部门市场投资过程（CMIP）过程挖掘任务书与实现路径（基于 PM4Py / Petri 网）

## 1. 题目与交付物整理（原题复述）

在过程设计阶段得到某个跨部门市场投资过程（CMIP）如下图所示，其中：

- 白色方框：一般活动
- 虚线：活动间异步消息交互
- 红色方框：需要同步的任务
- 蓝色椭圆：资源

在 CMIP 实施时，通过其所在的信息系统收集得到一个 CSV 格式的运行日志 `L`（附件：`Log_09.csv`）。

需要完成：

- 问题1：基于经典文献 *C. Liu, H. Li, S. Zhang, et al. Cross-department collaborative healthcare process model discovery from event logs. IEEE TASE, 2023, 20(3):2115-2125.* 中提出的方法，对事件日志 `L` 挖掘得到过程模型 `N`。
  - 挖掘过程需以 **Petri 网**为核心，详细阐述并编程实现。
  - 涉及：控制流模型、协作模式、集成模型。
  - 控制流发现涉及 Inductive Miner（参考链接： https://processintelligence.solutions/static/api/2.7.11/api.html#process-discovery-pm4py-discovery ）
- 问题2：对挖掘得到的 `N` 从 Fitness、Precision、F-measure 进行质量评价。
- 问题3：基于评价结果分析 `N` 质量低下原因（判断错误类型并详细阐述）。
- 问题4：基于 Petri 网建模一种策略，移除 `N` 中错误使 Fitness/Precision/F-measure 尽可能接近 1，并给出移除后的质量评价。
- 问题5：将该策略融入文献挖掘算法中，提出改进算法，使其能有效挖掘高质量跨部门过程模型，并通过日志 `L` 验证。
- 问题6：调研 PM4Py（Python），基于改进算法开发过程挖掘软件。
  - 输入：csv 或 xes 事件日志
  - 输出：可视化 Petri 网
  - 系统架构任选

本文件交付：

- 任务内容整理成 Markdown（含流程图文字复现）。
- 对需求与实现路径进行深度分析，并写入 Markdown。

---

## 2. 附：流程图内容的文字复现（根据提供图片）

### 2.1 流程名称

- 标题：**金融领域-市场投资-09**

### 2.2 参与部门（泳道/分区）

- 市场研究部门
- 风险评估部门
- 投资决策部门
- 交易执行部门
- 合规监控部门

### 2.3 资源（蓝色椭圆）

- 数据分析设备（有限资源）
- 会议室（有限资源）
- 市场信息报告（文档/产物型资源）
- 风险评估报告（文档/产物型资源）
- 交易报告（文档/产物型资源）

### 2.4 市场研究部门（白框活动 + 红框同步任务）

顺序控制流（实线箭头）：

1. 宏观经济分析
2. 行业趋势研究
3. 竞争对手分析
4. 投资机会识别
5. 市场信息通知
6. 生成市场信息报告
7. **投资决策**（红框：需要同步的任务；与“投资决策部门”泳道中的同名红框表示**同一个跨部门同步点**）

资源使用：

- 行业趋势研究 ——(占用资源)→ 数据分析设备
- 生成市场信息报告 ——(释放资源)→ 数据分析设备
- 投资机会识别 ——(占用资源)→ 会议室
- 生成市场信息报告 ——(释放资源)→ 会议室

产物：

- 生成市场信息报告 → 市场信息报告（生成/归档到文档资源）

跨部门异步消息：

- 市场信息通知 ——虚线→ 风险评估部门的“接收市场信息通知”（异步消息交互）。

### 2.5 风险评估部门

顺序控制流：

1. 接收市场信息通知
2. 风险识别
3. 风险量化
4. 发送风险评估通知
5. 报告存档

资源：

- 市场信息报告 → 风险识别（作为输入）
- 报告存档 → 风险评估报告（生成/归档）

跨部门异步消息：

- 发送风险评估通知 ——虚线“风险评估通知”→ 投资决策部门的“接受风险评估通知”

### 2.6 投资决策部门（含红框同步任务）

顺序控制流：

1. 接受风险评估通知
2. **投资决策**（红框：需要同步的任务；与“市场研究部门”泳道中的同名红框为**同一同步任务/同步点**）
3. 投资组合构建
4. 投资决策生成
5. 投资部门总结

资源：

- 风险评估报告 → 投资决策（作为输入）

跨部门异步消息：

- 投资决策生成 ——虚线“投资决策”→ 交易执行部门的“交易计划制定”

### 2.7 交易执行部门

顺序控制流：

1. 交易计划制定
2. 交易监控
3. 发送交易通知
4. 报告整合

资源：

- 报告整合 → 交易报告（生成/归档）

跨部门异步消息：

- 发送交易通知 ——虚线“交易通知”→ 合规监控部门的“接受交易通知”

### 2.8 合规监控部门（含分支）

顺序控制流：

1. 合规政策制定
2. 接受交易通知
3. 合规检查

分支（从“合规检查”向下分叉，图中标注“流程复杂/流程简单”）：

- 流程复杂 → 深入合规分析 → 详细合规报告编写
- 流程简单 → 普通合规报告编写

合并并结束：

- （两条分支汇合）→ 报告提交

资源使用：

- 合规检查 ——(占用资源)→ 数据分析设备
- 报告提交 ——(释放资源)→ 数据分析设备
- 合规政策制定 ——(占用资源)→ 会议室
- 报告提交 ——(释放资源)→ 会议室

资源输入：

- 交易报告 → 合规检查（作为输入）

### 2.9 流程图中强调的管理问题（黄气泡）

- 市场研究部门 / 合规监控部门：
  - 资源冲突
  - 会议室、数据分析设备为重要的有限资源

### 2.10 文字复现的语义约定（用于后续 Petri 网建模）

- **[红框同步任务]**
  - 图中“投资决策”以红框出现在市场研究部门与投资决策部门两条泳道，表示该任务需要跨部门同步协作。
  - 在 Petri 网中应被建模为：
    - 同一个同步 transition（跨泳道共享），或
    - 双方到达后的 AND-join 同步结构（握手协议）。
- **[虚线异步消息]**
  - 虚线表示发送与接收在时间上可分离，但存在因果约束：先发送后接收。
  - 在 Petri 网中应以“消息缓冲 place”建模：发送产生 token，接收消耗 token。
- **[蓝色资源]**
  - 会议室、数据分析设备属于有限容量共享资源，应以资源 place 的 token 容量约束并发。
  - 市场信息报告/风险评估报告/交易报告属于文档型资源，更接近“数据对象”；为了支持一致性检验，可同样用 place 表示其生成与消耗。

---

## 3. 事件日志 L（Log_09.csv）结构确认

### 3.1 字段

`Log_09.csv` 的表头为：

- `case_id`：流程实例编号
- `tran`：活动编码（活动名/任务名在日志中用 `T0、T1...` 等表示）
- `rec_msg`：接收的消息列表（字符串形式的 list）
- `send_msg`：发送的消息列表（字符串形式的 list）
- `req_res`：申请/占用的资源列表
- `rel_res`：释放/产出的资源列表
- `roles`：执行部门/角色列表（例如 `['Research']`）
- `timestamp`：时间戳

与论文（C. Liu et al., TASE 2023）中事件属性的对齐映射（用于复现其算法）：

- `#case(e)` ↔ `case_id`
- `#task(e)` ↔ `tran`
- `#rm(e)` ↔ `rec_msg`
- `#sm(e)` ↔ `send_msg`
- `#res(e)` ↔ `req_res`
- `#dep(e)` ↔ `roles`

说明：论文中 `#res(e)` 表示“执行时需要的资源集合”。本题日志将“资源占用”记录在 `req_res`，将“资源释放/产物生成”记录在 `rel_res`。

- 在复现论文的 **RM_WF_net** 建模时：
  - 对“互斥共享的有限资源”（如会议室、数据分析设备）建议主要使用 `req_res`（占用）作为 `#res(e)`；释放可用 `rel_res` 或通过“同一任务结束即释放”简化。
  - 对“文档型资源”（如风险评估报告）可用 `rel_res` 表示其生成，并用 `req_res` 表示其被后续任务消耗（更贴近数据对象流）。

### 3.2 日志片段的可观察协作关系（从样例行可见）

从样例可直接识别典型“消息握手/交接”模式：

- `T3` 发送 `m1`，`T5` 接收 `m1`
- `T8` 发送 `m2`，`T23` 接收 `m2`
- `T12` 发送 `m3`，`T13` 接收 `m3`
- `T16` 发送 `m4`，`T18` 接收 `m4`

资源请求/释放：

- `req_res` 中出现 `r1、r2`（资源占用）
- `rel_res` 出现 `riskReport`（风险报告资源被产出/释放），随后在决策部门中 `req_res` 出现 `riskReport`（作为输入被请求）

说明：日志中的 `tran` 编码与图中中文活动名存在映射缺口。

- 若仅要求算法与指标验证：可以将 `tran` 直接作为活动名称。
- 若需要“与图一致的语义模型”：需补充一份 `tran → 中文活动名` 的映射表（可后续人工建立）。

并且需要注意：

- `roles` 是列表（例如 `['Research']` 或 `['Research','Decision']`），这会直接影响“部门内子日志投影”和“同步任务识别”。
- `send_msg/rec_msg`、`req_res/rel_res` 是字符串形式的 list，必须先解析，否则无法抽取协作约束。

同步任务判定（与论文一致）：

- 若某事件满足 `|#dep(e)| >= 2`（即 `roles` 同时包含多个部门），则该事件对应的 `#task(e)` 应被识别为**同步任务**（task synchronization）。

---

## 4. 需求深度分析与实现路径（按问题1~6组织）

### 4.1 问题1：基于文献方法从日志挖掘跨部门协作过程模型 N（Petri 网）

#### 4.1.1 目标模型 N 的组成

依据文献思路（跨部门协作过程发现），最终模型可拆为三层并在 Petri 网上统一表达：

1. 控制流模型（Control-flow）：
   - 描述每个部门内部活动的顺序、并发、选择、循环等。
   - 用 Petri 网（或 WF-net）刻画。
2. 协作模式（Collaboration patterns）：
   - 描述跨部门的交互结构，例如：
     - 异步消息发送/接收（虚线）
     - 同步协作任务（红框，需要“双方/多方同步”）
     - 共享资源的争用（蓝色资源、容量约束）
3. 集成模型（Integration model）：
   - 将“部门内控制流 Petri 子网”与“消息/同步/资源 Petri 子网”组合成一个可执行/可回放的整体 Petri 网 `N`。

为严格对齐论文方法，需要把传统 WF-net 扩展为带资源与消息的扩展网：**RM_WF_nets**（论文 Definition 5）。

#### 4.1.1.1 RM_WF_nets（论文 Definition 5，对齐说明）

论文用 RM_WF_nets 来形式化跨部门协作过程（CCHP）与部门内过程（IHP）。

- Petri 网结构：`Σ = (P, T, F, M0)`
- 位置集合分解：`P = P_L ∪ P_R ∪ P_M`
  - `P_L`：逻辑库所（控制流）
  - `P_R`：资源库所（共享/互斥资源）
  - `P_M`：消息库所（异步消息缓冲）
- 弧集合分解：`F = F_L ∪ F_R ∪ F_M`
  - `F_L = (P_L × T) ∪ (T × P_L)`：控制流弧
  - `F_R = (P_R × T) ∪ (T × P_R)`：资源流弧
  - `F_M = (P_M × T) ∪ (T × P_M)`：消息流弧

在 RM_WF_nets 中，变迁激发规则与标准 WF-net 相同；资源/消息通过 place token 约束“可执行性”。

#### 4.1.1.2 本题 CMIP 与论文 CCHP 的对应关系

- 论文 CCHP 的三类协作行为：
  - 消息交互（message exchange）↔ 本题虚线消息
  - 资源共享（resource sharing）↔ 本题会议室/数据分析设备
  - 任务同步（task synchronization）↔ 本题红框“投资决策”

因此，本题应按 RM_WF_nets 作为最终模型 `N` 的形式基础，而不仅是“纯控制流 Petri 网”。

#### 4.1.2 日志预处理（关键）

- 事件时间：解析 `timestamp` 为 datetime
- 活动名：使用 `tran` 作为 `concept:name`
- 部门/角色：从 `roles` 提取，作为 `org:resource` 或 `org:role`
- 消息字段：`rec_msg`/`send_msg` 是字符串形式 list，需要 `ast.literal_eval`
- 资源字段：`req_res`/`rel_res` 同样 parse 为 list

建议统一抽象为扩展事件结构：

- `e = (case_id, act, role_set, ts, send_set, recv_set, req_set, rel_set)`

其中 `act=tran`，`role_set` 由 `roles` 解析得到。

与论文一致的**标准化目标**：

- 得到可按部门投影的事件日志集合 `{L_d}`（`d` 为部门/角色）。
- 得到可用于协作模式抽取的跨部门日志视角（包含 `#rm/#sm/#res/#dep`）。

此外要处理的日志问题：

- 同一 `case_id` 内可能跨部门交错发生（按 timestamp 排序）
- 有些 `roles` 可能是列表（例如 `['Research','Decision']`），需要定义归属规则：
  - 方案A：复制事件到多个部门视角（多视角日志）
  - 方案B：定义为“同步/联合执行事件”（更贴近红框语义）

#### 4.1.3 控制流发现：Inductive Miner 发现部门内 Petri 网

做法：按部门过滤日志（或按 `roles` 视角投影）得到每个部门子日志 `L_d`，对每个 `L_d` 用 Inductive Miner 发现 Petri 网 `N_d`。

- 推荐使用 IMf（Inductive Miner - infrequent）以便过滤噪声/低频路径，提高精确度。

产出：

- `N_Research, N_Risk, N_Decision, N_Transaction, N_Compliance` 及其初始标识/终止标识。

对齐论文的术语：这些部门内子模型在论文中称为 **IHP models（Intra-department Healthcare Process）**，其输出不是单纯 WF-net，而是 **RM_WF_net**：即先用 IM/SM 得到控制流 `(P_L, T, F_L)`，再把消息/资源信息补入得到 `(P_L∪P_M∪P_R, T, F_L∪F_M∪F_R)`。

#### 4.1.3.1 论文 Algorithm 1（IHP Model Discovery）在本题的落地

论文 Algorithm 1 的核心逻辑可以按以下“可编程步骤”实现：

1. **部门投影**：从全局日志 `L` 按 `#dep` 投影出单部门子日志 `L_d`。
2. **发现控制流 WF-net**：对 `L_d` 用 Inductive Miner（或 Split Miner）得到控制流结构 `(P_L, T, F_L)`。
3. **补入消息与资源库所**（遍历 `L_d` 中事件）：
   - 若 `#sm(e) != ∅`：把 `#sm(e)` 对应的消息加入 `P_M`，加弧 `(t, m)`。
   - 若 `#rm(e) != ∅`：把 `#rm(e)` 对应的消息加入 `P_M`，加弧 `(m, t)`。
   - 若 `#res(e) != ∅`：把资源加入 `P_R`，加弧 `(r, t)` 与 `(t, r)`（占用-释放）。
4. **设置初始标识**：`M0 = {i} ∪ P_R`（源库所与资源库所初始各 1 token）。
5. 返回部门 IHP 的 `RM_WF_net`。

注：本题日志中消息/资源字段是“集合”，实现时需将 list 展开为多个 message/resource place。

#### 4.1.4 协作模式发现：从消息与资源字段构建交互约束

1) 异步消息模式（send/receive）：

- 对每个消息 ID `m`：
  - 找到发送事件集 `S(m)`：包含 `m` 于 `send_msg`
  - 找到接收事件集 `R(m)`：包含 `m` 于 `rec_msg`
- 建立跨部门依赖：发送必须先于接收（同一 case 内）。

为避免“错误配对”（同一消息 ID 在不同 case/不同时间出现），建议以 `(case_id, message_id)` 为键进行配对；若同一 case 内同一 message_id 出现多次，则按时间最近原则配对。

Petri 网建模方式（消息缓冲 place）：

- 为每个消息 `m` 建立 place `p_m`：表示消息“在信箱中等待被消费”。
- 发送 transition `t_send` 向 `p_m` 放入 token
- 接收 transition `t_recv` 从 `p_m` 取走 token

这样可以保证：

- 没有发送就不能接收（提升 precision）
- 发送后可以延迟接收（异步语义）

对齐论文：这类跨部门消息交互对应论文的 **Message Exchange Pattern（Definition 6）**，其本质特征是“两个部门 RM_WF_nets 存在共同的消息 place”，即 `P_{M1} ∩ P_{M2} ≠ ∅`。

形式化条件（贴近论文 Definition 6）：设两个部门的 RM_WF_nets 分别为 `Σ1=(P1,T1,F1,M01)`、`Σ2=(P2,T2,F2,M02)`，则二者间存在消息交互模式当且仅当：

- `P_{L1} ∩ P_{L2} = ∅`
- `P_{M1} ∩ P_{M2} ≠ ∅`
- `P_{R1} ∩ P_{R2} = ∅`
- `T1 ∩ T2 = ∅`

2) 同步任务模式（红框）：

图中“投资决策”为同步任务，日志中也存在多角色同一事件（如 `roles=['Research','Decision']` 或者跨部门关键节点紧邻）。可用两种 Petri 建模：

- 同步 transition：同一个 transition 同时属于多个部门子网的同步点（组合时合并为同一 `t_sync`）。
- 握手协议：用两个 transition + 一个同步 place 让双方到达后才能继续（AND-join）。

同步任务的识别规则建议优先级：

- 若存在 `roles` 同时包含多个部门（如 `['Research','Decision']`），该事件优先视为同步任务候选。
- 若不存在多角色事件，则以“跨部门关键交互点”识别：例如风险评估通知到达后，投资决策前存在必须等待市场研究输出的结构（需结合直接跟随关系与消息约束推断）。

对齐论文：同步任务对应 **Task Synchronization Pattern（Definition 8）**，特征为 `T1 ∩ T2 ≠ ∅`（两个部门存在共同任务）。在事件日志层面，论文给出的直接判据是 `|#dep(e)| ≥ 2`。

形式化条件（贴近论文 Definition 8）：设两个部门的 RM_WF_nets 分别为 `Σ1`、`Σ2`，则二者间存在任务同步模式当且仅当：

- `P1 ∩ P2 = ∅`
- `T1 ∩ T2 ≠ ∅`

3) 共享资源模式（蓝色椭圆）：

- 对每个资源 `r` 建立资源 place `p_r`，token 数量表示资源容量。
  - 若未知容量：可先设为 1（强互斥），或根据日志最大并发估计容量。
- 资源占用：`req_res` 包含 `r` 的 transition 从 `p_r` 取 token。
- 资源释放：`rel_res` 包含 `r` 的 transition 向 `p_r` 放 token。

该建模可显式表达：

- 市场研究与合规监控对“会议室/数据分析设备”的竞争（减少不合理并发，提高 precision）。

对齐论文：共享资源对应 **Resource Sharing Pattern（Definition 7）**，其假设是资源**互斥使用**（exclusive use）：一个部门任务占用资源时，其他部门必须等待直到释放。

形式化条件（贴近论文 Definition 7）：设两个部门的 RM_WF_nets 分别为 `Σ1`、`Σ2`，则二者间存在资源共享模式当且仅当：

- `P_{L1} ∩ P_{L2} = ∅`
- `P_{M1} ∩ P_{M2} = ∅`
- `P_{R1} ∩ P_{R2} ≠ ∅`
- `T1 ∩ T2 = ∅`

#### 4.1.4.1 论文 Algorithm 2（Collaboration Pattern Discovery）在本题的落地

论文 Algorithm 2 在“日志层面”给出三类协作模式的发现规则（概要对齐）：

- **消息交互（message exchange）**：若同一 case 内跨部门事件对 `(e_i, e_j)` 满足“发送导致接收”的结构关系，则构建消息 place 并连接 `(t_i → p_m → t_j)`。
- **资源共享（resource sharing）**：若跨部门事件对共享同一资源，则构建资源 place 并连接互斥弧（使资源 token 在跨部门间互斥流转）。
- **任务同步（task synchronization）**：若 `|#dep(e_i)| ≥ 2`，则把 `#task(e_i)` 加入同步任务集合。

在本题实现上，考虑到日志已经显式记录 `send_msg/rec_msg` 与 `req_res/rel_res`，可采用“更直接且更稳健”的抽取方式：

- 直接用 `send_msg/rec_msg` 配对发现消息 place 与其连接变迁。
- 直接用 `req_res/rel_res` 统计发现共享资源 place 与其互斥连接。
- 直接用 `|roles| ≥ 2` 识别同步任务。

该实现与论文的形式化结果一致，但更依赖日志的显式字段，从而更适用于本题给定的 CSV 日志结构。

#### 4.1.5 集成模型：把部门子网 + 消息/资源/同步子网组合为整体 Petri 网 N

对齐论文 **Definition 9（Model Integration）**：

- 输入：各部门 IHP 的 RM_WF_nets `Σ_i = (P_i, T_i, F_i, M0_i)`，以及协作模式网集合 `Σ_C`。
- 集成输出：`Σ = (P, T, F, M0)`
  - `P = P_M ∪ P_R ∪ P_L ∪ P_C`（对 place 集合做并集，并把协作模式产生的 place 合入）
  - `T = T_C ∪ T_1 ∪ ... ∪ T_n`
  - `F = F_M ∪ F_R ∪ F_L ∪ F_C`
  - `M0 = P_s ∪ P_R`（所有源逻辑库所 + 所有资源库所初始各 1 token）

集成要点：

- **消息 place 与资源 place 是跨部门共享的**（union 后按同名合并），从而把跨部门因果/互斥约束注入全局网。
- **同步任务**需确保在集成后不被拆成“各走各的”，否则会降低 precision 或造成不可回放。

#### 4.1.5.1 组合实现要点（补充说明）

核心是“Petri 网组合（composition）”，其工程化表述为：

- **部门内控制流**：保持各 `N_d` 的结构
- **跨部门交互**：在相应 transition 之间增加消息 place 或同步结构
- **共享资源**：在相应 transition 处增加资源 place 的弧

组合后应满足：

- 有全局初始标识 `M0`（可由各子网初始 place 合并或并行拆分）
- 有全局终止标识 `Mf`
- 能在日志上进行对齐/回放（conformance checking）

#### 4.1.6 编程实现建议（PM4Py）

实现建议分为 4 个模块：

- `io.py`：读 csv/xes，标准化为 PM4Py event log
- `discover_local.py`：按 `roles` 投影并用 Inductive Miner 发现各部门 Petri 网
- `discover_collab.py`：从消息/资源字段生成交互约束结构（消息 place、资源 place、同步点集合）
- `compose.py`：将子网与约束组合为集成 Petri 网 `N`

#### 4.1.6.1 可执行落地清单（把论文 Algorithm 1/2/Definition 9 映射到工程步骤）

说明：当前工作区环境中暂未安装 `pm4py`（我在本机检测到 `import pm4py` 失败）。因此本节给出**可执行的实现步骤清单**与“应调用的 PM4Py 能力类别”，具体函数名以你给的 PM4Py API 链接为准。

1) 环境与依赖

- Python 版本：建议 3.9+。
- 依赖：
  - `pandas`：读取 CSV、时间解析。
  - `pm4py`：过程发现、对齐/回放、可视化。

2) CSV 日志标准化（对应论文 Step: Medical Event Log Collection and Standardization）

目标：将 `Log_09.csv` 转为“事件表”（DataFrame）并形成 event log。

- 关键字段映射：
  - Case：`case_id`
  - Activity：`tran`
  - Timestamp：`timestamp`
  - Department：`roles`
  - Received messages：`rec_msg`
  - Sent messages：`send_msg`
  - Required resources：`req_res`
  - Released/produced objects：`rel_res`

实现要点：

- `rec_msg/send_msg/req_res/rel_res/roles` 为字符串形式 list，必须先解析为 Python list。
- 同一 `case_id` 内按 `timestamp` 排序。

3) 部门投影（对应论文 IHP Model Discovery 的输入准备）

对每个部门 `d`（例如 Research/Risk/Decision/Transaction/Compliance）：

- 构造子日志 `L_d`：筛选 `roles` 包含 `d` 的事件。
- 同步事件的处理（与论文一致，`|roles|>=2`）：
  - 方案A（推荐用于保持日志完整）：把事件复制到每个相关部门的 `L_d`（这样每个部门视角都看得到同步点），并在事件属性中保留原 `roles` 以便后续识别同步。
  - 方案B：只保留到“主部门”，但会弱化同步模式发现，除非单独做同步补偿。

4) IHP 发现（复现论文 Algorithm 1 的第 2 行 + 7~15 行“补入消息/资源”）

- 控制流发现：对 `L_d` 使用 Inductive Miner 发现 WF-net 控制流 `(P_L, T, F_L)`。
- 消息 place（`P_M`）注入：
  - 对每个任务 `t`，遍历 `L_d` 中所有 `#task(e)=t` 的事件；
  - 对 `#sm(e)` 中的每个消息 `m`：建立/复用 place `p_m`，加弧 `(t, p_m)`；
  - 对 `#rm(e)` 中的每个消息 `m`：建立/复用 place `p_m`，加弧 `(p_m, t)`。
- 资源 place（`P_R`）注入：
  - 对 `#res(e)`（本题默认取 `req_res`）中的每个资源 `r`：建立/复用 place `p_r`，加弧 `(p_r, t)` 和 `(t, p_r)`。
- 初始标识：
  - `M0` 包含各部门 source place（逻辑起点）与资源 place（每个资源 1 token，表示互斥容量=1）。

得到部门 IHP：`Σ_d = (P_L∪P_M∪P_R, T, F_L∪F_M∪F_R, M0)`。

5) 协作模式发现（复现论文 Definition 6-8 与 Algorithm 2 的输出效果）

由于本题日志显式给出消息/资源/多部门任务，可采用“字段驱动”的协作抽取（等价于论文发现结果）：

- **消息交互模式**：如果同一 case 中存在 `m` 的发送事件与接收事件，则在全局层面共享同一个消息 place `p_m`，并确保发送向其放 token、接收从其取 token。
- **资源共享模式**：如果资源 `r` 出现在多个部门事件的 `req_res` 中，则该 `p_r` 为跨部门共享资源 place（互斥）。
- **任务同步模式**：如果存在事件满足 `|roles|>=2`，其 `tran` 对应任务为同步任务候选；集成时应保证该任务在相关部门间共享同步结构。

6) 集成模型（复现论文 Definition 9）

把所有部门 `Σ_d` 与协作模式子网 `Σ_C` 做集合并集集成：

- place 合并规则：同名的消息/资源 place 合并为同一 place（例如统一命名：`MSG:m1`、`RES:r1`）。
- 同步任务合并规则：同一同步任务在多部门子网中出现时，集成后必须满足同步语义：
  - 共享一个同步 transition；或
  - 用同步 place/AND-join 结构强制双方到达后才能继续。

7) 输出物（建议作为问题1的“编程实现交付”）

- `N0`：初始发现的集成 RM_WF_net（Petri 网）
- `N1`：修复后的高质量 RM_WF_net（问题4/5）
- 可视化：`N0.svg/N1.svg`（或 png）
- 指标报告：`metrics.json/csv`（fitness/precision/F）

---

### 4.2 问题2：对 N 的质量评价（Fitness / Precision / F-measure）

#### 4.2.1 Fitness（拟合度）

含义：模型能否重放日志中的行为。

推荐指标：

- 基于对齐（alignments）的 fitness 或基于 token replay 的 fitness。

对齐论文：Fitness 使用 [28]（Adriansyah et al., 2011）中基于代价的 fitness 定义。

#### 4.2.2 Precision（精确度）

含义：模型是否允许了太多日志中未出现的行为（过度泛化）。

推荐指标：

- 基于对齐的 precision（ETConformance）或 PM4Py 提供的 precision 评估器。

对齐论文：Precision 使用 [29]（Adriansyah et al., 2012）对齐精确度（alignment-based precision）。

#### 4.2.3 F-measure

综合度量：

- `F = 2 * Fitness * Precision / (Fitness + Precision)`

评估实现落点：

- 统一基于同一份事件日志 `L` 和模型 `N` 计算三项指标。

#### 4.2.4 指标计算的工程化建议（用于问题2的编程实现说明）

- 建议使用“对齐（alignments）”统一支撑 fitness 与 precision（与论文引用 [28][29] 一致）。
- 输出应包含：
  - 总体指标（全局 log）
  - 分部门指标（可选，用于定位质量低下来自哪个子网）
  - 对齐代价/偏差统计（用于问题3错误诊断）

---

### 4.3 问题3：质量低下原因分析（错误类型判定）

当 `N` 质量低下时，典型错误可分为三类（在跨部门场景更突出）：

#### 4.3.1 控制流层错误

- 缺失路径（underfitting）：
  - 由于日志不完整/存在异常导致 IM 发现模型缺少必要分支 → fitness 下降
- 伪并发（false parallelism）：
  - IM 把实际存在先后依赖的活动误判为可并发 → precision 下降
- 错误循环/错误选择：
  - 将稀有返工行为归纳成循环，导致大量未观测行为被允许 → precision 下降

#### 4.3.2 协作层错误（消息/同步）

- 消息未约束（message causality 缺失）：
  - 未用 Petri 网 place 表达“先发后收”，导致接收可无条件发生 → precision 下降
- 同步任务被当作普通活动：
  - 红框任务（投资决策）需要双方同步到达，但模型未建模同步点 →
    - 可能出现死锁/不一致 token 流 → fitness 下降
    - 或允许单方越过同步点 → precision 下降

#### 4.3.3 资源层错误（共享资源竞争）

- 忽略有限资源容量：
  - 会议室/数据分析设备被当作无限资源，导致不合理并发 → precision 下降
- 资源请求/释放不匹配：
  - req/rel 关系没被正确映射到 Petri 网弧，导致 token 不守恒 → fitness 下降

对齐论文“正确性”判据（文中对 [15] 的总结，可用于定位错误类型）：

- **[消息正确性]** 模型结束时 message places 不应残留 token（否则表示“发了但没人收/收了但没发”等异常）。
- **[部门子网正确性]** 每个部门的 WF-net 应 sound；结束时 token 应仅在各部门 sink place 中，且数量与 source 一致。
- **[无死变迁]** 不应存在 dead transitions。

这些正确性问题往往与质量指标的关系：

- message place 残留 token / 资源 token 不守恒 → 回放对齐代价升高 → fitness 下降。
- 缺失消息/资源/同步约束 → 允许大量未观测行为 → precision 下降。

#### 4.3.4 面向实现的“错误定位流程”（如何从评估结果反推出错误）

为了让问题3具备可操作性，建议在计算指标时同时采集以下证据：

1) 基于对齐的偏差分类（log-move / model-move）

- **log-move 多**：日志事件无法被模型解释 → 通常是控制流缺失、同步/资源/消息约束过强、或模型存在死锁。
- **model-move 多**：模型允许但日志没发生 → 通常是模型过度泛化（伪并发、错误循环、缺失协作约束）。

2) Token replay / 终止标识检查（对齐论文正确性条件）

- **message place 残留 token**：
  - 可能原因：只建了发送没建接收；或接收不受消息约束（接收可无 token 也能走）。
- **resource place token 异常**：
  - 可能原因：req/rel 弧建错；释放事件缺失；资源容量估计不合理。
- **部门 sink/source token 不一致**：
  - 可能原因：部门子网不 sound、或者集成时把 source/sink 连接破坏。

3) 结构性错误检测（静态）

- **dead transitions**：没有任何可执行路径可触发 → 集成约束错误或控制流挖掘错误。
- **非期望的并发结构**：日志中顺序显著但模型为并发（伪并发）。

建议把错误输出成清单：`{错误类型, 涉及任务/消息/资源, 证据(对齐统计/残留token/死变迁), 影响指标}`。

---

### 4.4 问题4：基于 Petri 网的“错误移除策略”（模型修复/约束增强）

目标：在尽可能保持高 fitness 的同时，显著提升 precision，使 F-measure 接近 1。

提出策略：**约束增强型修复（Constraint-Enhanced Petri Net Repair, CE-PNR）**。

#### 4.4.1 修复输入

- 初始模型 `N0`（由问题1挖掘得到的集成 Petri 网）
- 日志 `L`
- 从日志可直接抽取的约束：
  - 消息先后约束（send-before-receive）
  - 资源容量约束（seize/release）
  - 同步点约束（红框任务）

#### 4.4.2 修复操作（Petri 网层面的可执行变换）

- 消息约束注入：为每个消息 `m` 增加 place `p_m` 并连接发送/接收 transition。
- 资源约束注入：为每个资源 `r` 增加 place `p_r`，并在 `req_res/rel_res` 对应 transition 处加弧。
- 同步点修复：
  - 识别“同步任务集合” `T_sync`（如投资决策），将跨部门对应 transition 合并或用 AND-join 结构同步。
- 伪并发抑制：
  - 若日志中 A 总是在 B 前发生（跨 case 统计显著），则在 Petri 网中加因果约束（place/弧）抑制 A||B。
- 低频路径清理：
  - 对极低频的直接跟随关系（DFG 边）进行过滤后重新挖掘局部网（IMf），减少过度泛化。

#### 4.4.3 让策略“可实现”的决策规则（建议写入问题4的技术说明）

1) 消息错误修复（对应 message place）

- 触发条件：出现“接收但无发送”的对齐偏差，或 message place 终止时残留 token。
- 修复算子：
  - 若缺失弧：补齐 `(t_send, p_m)` 或 `(p_m, t_recv)`。
  - 若消息命名混乱：统一消息 place 命名并合并。

2) 资源错误修复（对应 resource place）

- 触发条件：token replay 显示资源 token 不守恒、或出现不合理并发导致 precision 低。
- 修复算子：
  - 为所有 `req_res` 的任务补齐 `(p_r, t)` 与 `(t, p_r)`。
  - 资源容量估计：
    - 默认 1（论文资源互斥假设）；
    - 若日志显示同资源在同一时间窗出现明显并发，可把容量调大（但会降低 precision）。

3) 同步错误修复（红框任务）

- 触发条件：同步任务在多部门被建成“各走各的”（对齐出现大量 model-move 或出现死锁）。
- 修复算子：
  - 合并同步 transition；或
  - 建立 AND-join 同步 place，使双方到达后才放行。

4) 伪并发修复

- 触发条件：对齐/统计显示 A 几乎总在 B 前（强因果），但模型允许 A||B。
- 修复算子：新增逻辑 place，把 `A → place → B` 串起来，消除并发。

#### 4.4.4 修复后的再评价

- 对修复后的 `N1` 重新计算 Fitness / Precision / F-measure
- 若 precision 提升但 fitness 大幅下降：说明约束过强，需要放宽容量/同步识别规则或保留必要隐藏变迁。

---

### 4.5 问题5：把修复策略融入文献算法，形成改进挖掘算法并用 L 验证

提出改进算法：**CMIP-IMR（Constraint-aware Multi-department Inductive Miner with Repair）**

#### 4.5.1 算法框架（高层）

1. 预处理：解析日志字段、按 case 排序、抽取部门视角
2. 初始发现：对每部门用 IMf 发现局部 Petri 网
3. 协作抽取：抽取消息依赖、同步点候选、共享资源容量估计
4. 集成组合：合并为初始集成网 `N0`
5. 质量评价：计算 Fitness/Precision/F
6. 约束增强修复：执行 CE-PNR 得到 `N1`
7. 再评价：若 F-measure 未达到阈值则迭代（可限制迭代次数）

#### 4.5.2 改进算法的“停止条件/阈值建议”（让问题5更可验证）

- 目标阈值：`F >= 0.95`（或课程要求的更高值）。
- 迭代停止条件：
  - 达到阈值；或
  - 连续两次迭代的 `F` 提升小于 `ε`（例如 0.005）；或
  - fitness 下降超过上限（例如下降 0.02）则回退上一次修复。

#### 4.5.3 用 Log_09.csv 的验证报告结构（建议作为最终报告输出）

- `N0` 指标：fitness / precision / F
- `N1` 指标：fitness / precision / F
- 主要修复动作摘要：
  - 修复了哪些消息 place、哪些资源 place、哪些同步点
  - 伪并发被抑制的关键任务对
- 对齐偏差对比：log-move/model-move 是否显著下降

#### 4.5.4 相比“仅 IM + 简单组合”的改进点

- 用“消息 place + token 语义”把异步交互变成可检验的 Petri 约束
- 用“资源 place + 容量”把跨部门资源冲突显式化
- 用“同步点结构”保证红框任务的协同一致性
- 用“评价驱动的修复循环”把质量指标直接纳入发现流程

#### 4.5.5 用日志 L 的验证方式

- 将 `N0` 与 `N1` 的 Fitness/Precision/F-measure 进行对比
- 重点验证：
  - Precision 是否显著提升（是否减少了不合理并发/无消息接收等行为）
  - Fitness 是否保持较高（约束不会把真实行为排除）

---

### 4.6 问题6：基于 PM4Py 的过程挖掘软件设计（集成改进算法）

#### 4.6.1 功能需求

- 输入：
  - CSV（至少支持本题字段集）
  - XES（通用）
- 参数：
  - IM 噪声阈值（IMf）
  - 资源容量估计策略（默认 1 或基于并发估计）
  - 同步点识别策略（基于多角色事件/基于消息关联/人工指定）
- 输出：
  - Petri 网可视化（SVG/PNG）
  - 导出 PNML
  - 指标报告：Fitness/Precision/F

#### 4.6.2 推荐系统架构（轻量易交付）

- 前端/界面：Streamlit（单机快速开发，适合课程/作业交付）
- 后端服务层（Python 模块）：
  - `app.py`：UI
  - `services/ingest.py`：导入、字段映射、日志转换
  - `services/discovery.py`：CMIP-IMR 挖掘
  - `services/evaluation.py`：质量评价
  - `services/visualize.py`：Petri 网可视化与导出
- 运行方式：`streamlit run app.py`

#### 4.6.3 软件交互与配置建议（让问题6更像“软件设计文档”）

- 日志导入：
  - CSV：提供字段映射配置（下拉选择：case/activity/timestamp/roles/send/rec/req/rel），以便支持非本题格式。
  - XES：直接读取标准字段；若有扩展属性（消息/资源/部门）则自动识别。
- 参数面板：
  - 发现器：IM / IMf（阈值）/ SM（可选）
  - 资源容量：默认 1；或“从日志估计”
  - 同步识别：`|roles|>=2`（默认启用）；或手动指定同步任务名
  - 修复开关：是否启用 CE-PNR；阈值与最大迭代次数
- 输出面板：
  - `N0` 可视化 + 指标
  - `N1` 可视化 + 指标
  - 错误诊断报告（问题3的输出：错误清单 + 证据）
  - 导出：PNML / SVG / 指标 JSON

#### 4.6.4 可视化实现要点

- 使用 PM4Py 自带 Petri net visualizer 输出 SVG/PNG
- UI 显示：
  - 部门内子网（可选）
  - 集成网 N0
  - 修复后 N1
  - 指标对比表

---

## 5. 当前状态与下一步

已完成：

- 找到并确认日志 `Log_09.csv` 的字段结构。
- 对流程图进行文字复现（部门/活动/资源/消息/同步点）。

下一步（如继续实施）：

- 基于 PM4Py 编写实际代码：从 `Log_09.csv` 自动发现 `N0`、计算指标；实现 CE-PNR 得到 `N1` 并再评价。
- （可选但强烈建议）补充 `tran(T0..Txx) → 中文活动名` 映射，使挖掘结果与图中语义完全一致。
